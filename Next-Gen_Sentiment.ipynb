{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Sentiment Analysis: Outperforming NLTK, FinBERT, and TextBlob with Hybrid Word Embeddings and VADER Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>7:51  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer recommended buying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>7:33  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer rings the lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>7:25  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"We'll pay more for the earnings of the non-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>4:24  PM ET Fri, 17 July 2020</td>\n",
       "      <td>Keith Bliss, IQ Capital CEO, joins \"Closing Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>7:36  PM ET Thu, 16 July 2020</td>\n",
       "      <td>\"Look for the stocks of high-quality companies...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0  Jim Cramer: A better way to invest in the Covi...   \n",
       "1     Cramer's lightning round: I would own Teradyne   \n",
       "3  Cramer's week ahead: Big week for earnings, ev...   \n",
       "4  IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "5  Wall Street delivered the 'kind of pullback I'...   \n",
       "\n",
       "                             Time  \\\n",
       "0   7:51  PM ET Fri, 17 July 2020   \n",
       "1   7:33  PM ET Fri, 17 July 2020   \n",
       "3   7:25  PM ET Fri, 17 July 2020   \n",
       "4   4:24  PM ET Fri, 17 July 2020   \n",
       "5   7:36  PM ET Thu, 16 July 2020   \n",
       "\n",
       "                                         Description  \n",
       "0  \"Mad Money\" host Jim Cramer recommended buying...  \n",
       "1  \"Mad Money\" host Jim Cramer rings the lightnin...  \n",
       "3  \"We'll pay more for the earnings of the non-Co...  \n",
       "4  Keith Bliss, IQ Capital CEO, joins \"Closing Be...  \n",
       "5  \"Look for the stocks of high-quality companies...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load financial news dataset from CSV file\n",
    "df = pd.read_csv('cnbc_headlines.csv')\n",
    "\n",
    "# Drop rows where 'content' is NaN\n",
    "df.dropna(subset=['Headlines'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simranjeetsingh1497/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>7:51  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer recommended buying...</td>\n",
       "      <td>jim cramer better way invest covid vaccine gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>7:33  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer rings the lightnin...</td>\n",
       "      <td>cramers lightning round would teradyne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>7:25  PM ET Fri, 17 July 2020</td>\n",
       "      <td>\"We'll pay more for the earnings of the non-Co...</td>\n",
       "      <td>cramers week ahead big week earnings even bigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>4:24  PM ET Fri, 17 July 2020</td>\n",
       "      <td>Keith Bliss, IQ Capital CEO, joins \"Closing Be...</td>\n",
       "      <td>iq capital ceo keith bliss says tech healthcar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>7:36  PM ET Thu, 16 July 2020</td>\n",
       "      <td>\"Look for the stocks of high-quality companies...</td>\n",
       "      <td>wall street delivered kind pullback ive waitin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0  Jim Cramer: A better way to invest in the Covi...   \n",
       "1     Cramer's lightning round: I would own Teradyne   \n",
       "3  Cramer's week ahead: Big week for earnings, ev...   \n",
       "4  IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "5  Wall Street delivered the 'kind of pullback I'...   \n",
       "\n",
       "                             Time  \\\n",
       "0   7:51  PM ET Fri, 17 July 2020   \n",
       "1   7:33  PM ET Fri, 17 July 2020   \n",
       "3   7:25  PM ET Fri, 17 July 2020   \n",
       "4   4:24  PM ET Fri, 17 July 2020   \n",
       "5   7:36  PM ET Thu, 16 July 2020   \n",
       "\n",
       "                                         Description  \\\n",
       "0  \"Mad Money\" host Jim Cramer recommended buying...   \n",
       "1  \"Mad Money\" host Jim Cramer rings the lightnin...   \n",
       "3  \"We'll pay more for the earnings of the non-Co...   \n",
       "4  Keith Bliss, IQ Capital CEO, joins \"Closing Be...   \n",
       "5  \"Look for the stocks of high-quality companies...   \n",
       "\n",
       "                                     Cleaned_Content  \n",
       "0  jim cramer better way invest covid vaccine gol...  \n",
       "1             cramers lightning round would teradyne  \n",
       "3  cramers week ahead big week earnings even bigg...  \n",
       "4  iq capital ceo keith bliss says tech healthcar...  \n",
       "5  wall street delivered kind pullback ive waitin...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)       # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)   # Remove special characters\n",
    "    text = text.lower()                       # Lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Assuming the dataset has a column named 'content' for analysis\n",
    "df['Cleaned_Content'] = df['Headlines'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>jim cramer better way invest covid vaccine gol...</td>\n",
       "      <td>[invest]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>cramers lightning round would teradyne</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lightning, teradyne]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>cramers week ahead big week earnings even bigg...</td>\n",
       "      <td>[big, bigger]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>iq capital ceo keith bliss says tech healthcar...</td>\n",
       "      <td>[iq]</td>\n",
       "      <td>[says]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>wall street delivered kind pullback ive waitin...</td>\n",
       "      <td>[wall, ive]</td>\n",
       "      <td>[delivered, waiting, says]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>Markets lack Christmas cheer</td>\n",
       "      <td>markets lack christmas cheer</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>Cramer Remix: The biggest mistake you can make...</td>\n",
       "      <td>cramer remix biggest mistake make taxes stock ...</td>\n",
       "      <td>[biggest]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>Cramer says owning too many stocks and too lit...</td>\n",
       "      <td>cramer says owning many stocks little cash set...</td>\n",
       "      <td>[many, little]</td>\n",
       "      <td>[says, owning, set]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>Cramer: I helped investors through the 2010 fl...</td>\n",
       "      <td>cramer helped investors flash crash following ...</td>\n",
       "      <td>[flash, key]</td>\n",
       "      <td>[helped, following]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>Cramer: Never buy a stock all at once — you'll...</td>\n",
       "      <td>cramer never buy stock youll almost definitely...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[buy, get, burned]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Headlines  \\\n",
       "0     Jim Cramer: A better way to invest in the Covi...   \n",
       "1        Cramer's lightning round: I would own Teradyne   \n",
       "3     Cramer's week ahead: Big week for earnings, ev...   \n",
       "4     IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "5     Wall Street delivered the 'kind of pullback I'...   \n",
       "...                                                 ...   \n",
       "3075                       Markets lack Christmas cheer   \n",
       "3076  Cramer Remix: The biggest mistake you can make...   \n",
       "3077  Cramer says owning too many stocks and too lit...   \n",
       "3078  Cramer: I helped investors through the 2010 fl...   \n",
       "3079  Cramer: Never buy a stock all at once — you'll...   \n",
       "\n",
       "                                        Cleaned_Content      Adjectives  \\\n",
       "0     jim cramer better way invest covid vaccine gol...        [invest]   \n",
       "1                cramers lightning round would teradyne              []   \n",
       "3     cramers week ahead big week earnings even bigg...   [big, bigger]   \n",
       "4     iq capital ceo keith bliss says tech healthcar...            [iq]   \n",
       "5     wall street delivered kind pullback ive waitin...     [wall, ive]   \n",
       "...                                                 ...             ...   \n",
       "3075                       markets lack christmas cheer              []   \n",
       "3076  cramer remix biggest mistake make taxes stock ...       [biggest]   \n",
       "3077  cramer says owning many stocks little cash set...  [many, little]   \n",
       "3078  cramer helped investors flash crash following ...    [flash, key]   \n",
       "3079  cramer never buy stock youll almost definitely...              []   \n",
       "\n",
       "                           Verbs  \n",
       "0                             []  \n",
       "1          [lightning, teradyne]  \n",
       "3                             []  \n",
       "4                         [says]  \n",
       "5     [delivered, waiting, says]  \n",
       "...                          ...  \n",
       "3075                      [lack]  \n",
       "3076                          []  \n",
       "3077         [says, owning, set]  \n",
       "3078         [helped, following]  \n",
       "3079          [buy, get, burned]  \n",
       "\n",
       "[2800 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Extend the custom lexicon with additional domain-specific words\n",
    "custom_lexicon = {\n",
    "    'good': 1.0,\n",
    "    'great': 1.5,\n",
    "    'excellent': 1.5,\n",
    "    'bad': -1.0,\n",
    "    'poor': -1.5,\n",
    "    'big': 0.5,\n",
    "    'week': 0.0,\n",
    "    'earnings': 0.0,\n",
    "    'stay long': 1.0,\n",
    "    'turn': 0.5,\n",
    "    'turning point': 1.0,\n",
    "    'concern': -0.5,\n",
    "    'uncertainty': -1.0,\n",
    "    'buy':1.0,\n",
    "    'lands':1.0,\n",
    "    'invested':1.0,\n",
    "    'bullish':1.0,\n",
    "    'unusual':-0.5,\n",
    "    'authenticated':0.5,\n",
    "    'Conagra':0.1,\n",
    "    'revamping':0.1,\n",
    "    'money':0.5,\n",
    "    'unprecedented':-0.5,\n",
    "    'using': 0.5,\n",
    "    'technology': 0.5,\n",
    "    'effective': 1.0,\n",
    "    'successful': 1.5,\n",
    "    'beneficial': 1.5,\n",
    "    'coronavirus': 0.0,  # Neutral in this context\n",
    "    'contact tracing': 1.0,\n",
    "    'surged':1.0,\n",
    "    'restrictions':-0.5,\n",
    "    'recovery':0.5,\n",
    "    'thumbs':0.4,\n",
    "    'mirror':0.5,\n",
    "    'acceleration':0.5,\n",
    "    'highs':0.1,\n",
    "    'higher':0.4,\n",
    "    'wait':0.3,\n",
    "    'bull':0.1,\n",
    "    'golden':0.1,\n",
    "    'normal':0.1,\n",
    "    'reacts':0.1,\n",
    "    'despite':-0.1,\n",
    "    'overbought':0.1,\n",
    "    'cautions':0.5,\n",
    "    \"can't\": -0.9, \n",
    "    \"without\":-0.1,\n",
    "    'helped':0.1,\n",
    "    'record':0.1,\n",
    "    'surpassed':0.3,\n",
    "    'diverse':0.1,\n",
    "    'behind':-0.1,\n",
    "    'fits':0.3,\n",
    "    'rotating':-0.3,\n",
    "    'leading':0.8,\n",
    "    'rebound':0.3,\n",
    "    'bailed':-0.1,\n",
    "    'out':-0.3,\n",
    "    'rough':-0.5,\n",
    "    'deal':0.2,\n",
    "    'minimal':0.1,\n",
    "    'most':0.09,\n",
    "    'legit':0.1,\n",
    "    'lasting':0.1,\n",
    "    'prefer':0.01,\n",
    "    'latest':0.1,\n",
    "    'lead':0.1,\n",
    "    'powering':0.1,\n",
    "    'upside':0.1,\n",
    "    'more':0.01,\n",
    "}\n",
    "\n",
    "# Function to extract adjectives and verbs\n",
    "def extract_adj_verbs(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    adjectives = [word for word, tag in tagged_words if tag in ('JJ', 'JJR', 'JJS')]\n",
    "    verbs = [word for word, tag in tagged_words if tag.startswith('VB')]\n",
    "    \n",
    "    return adjectives, verbs\n",
    "    \n",
    "# Apply the function to extract adjectives and verbs\n",
    "df['Adjectives'], df['Verbs'] = zip(*df['Cleaned_Content'].apply(extract_adj_verbs))\n",
    "\n",
    "# Display the DataFrame with the new sentiment column\n",
    "df[['Headlines', 'Cleaned_Content', 'Adjectives', 'Verbs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>FinBERT_Sentiment</th>\n",
       "      <th>Enhanced_NLTK_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>jim cramer better way invest covid vaccine gol...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>cramers lightning round would teradyne</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>cramers week ahead big week earnings even bigg...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>iq capital ceo keith bliss says tech healthcar...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>wall street delivered kind pullback ive waitin...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>Markets lack Christmas cheer</td>\n",
       "      <td>markets lack christmas cheer</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>Cramer Remix: The biggest mistake you can make...</td>\n",
       "      <td>cramer remix biggest mistake make taxes stock ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>Cramer says owning too many stocks and too lit...</td>\n",
       "      <td>cramer says owning many stocks little cash set...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>Cramer: I helped investors through the 2010 fl...</td>\n",
       "      <td>cramer helped investors flash crash following ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>Cramer: Never buy a stock all at once — you'll...</td>\n",
       "      <td>cramer never buy stock youll almost definitely...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Headlines  \\\n",
       "0     Jim Cramer: A better way to invest in the Covi...   \n",
       "1        Cramer's lightning round: I would own Teradyne   \n",
       "3     Cramer's week ahead: Big week for earnings, ev...   \n",
       "4     IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "5     Wall Street delivered the 'kind of pullback I'...   \n",
       "...                                                 ...   \n",
       "3075                       Markets lack Christmas cheer   \n",
       "3076  Cramer Remix: The biggest mistake you can make...   \n",
       "3077  Cramer says owning too many stocks and too lit...   \n",
       "3078  Cramer: I helped investors through the 2010 fl...   \n",
       "3079  Cramer: Never buy a stock all at once — you'll...   \n",
       "\n",
       "                                        Cleaned_Content FinBERT_Sentiment  \\\n",
       "0     jim cramer better way invest covid vaccine gol...          Positive   \n",
       "1                cramers lightning round would teradyne           Neutral   \n",
       "3     cramers week ahead big week earnings even bigg...           Neutral   \n",
       "4     iq capital ceo keith bliss says tech healthcar...           Neutral   \n",
       "5     wall street delivered kind pullback ive waitin...           Neutral   \n",
       "...                                                 ...               ...   \n",
       "3075                       markets lack christmas cheer          Negative   \n",
       "3076  cramer remix biggest mistake make taxes stock ...          Negative   \n",
       "3077  cramer says owning many stocks little cash set...          Negative   \n",
       "3078  cramer helped investors flash crash following ...          Positive   \n",
       "3079  cramer never buy stock youll almost definitely...           Neutral   \n",
       "\n",
       "     Enhanced_NLTK_Sentiment  \n",
       "0                   Positive  \n",
       "1                    Neutral  \n",
       "3                   Positive  \n",
       "4                    Neutral  \n",
       "5                    Neutral  \n",
       "...                      ...  \n",
       "3075                Negative  \n",
       "3076                Negative  \n",
       "3077                Negative  \n",
       "3078                Positive  \n",
       "3079                Positive  \n",
       "\n",
       "[2800 rows x 4 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Load FinBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "# Define sentiment analysis pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def enhanced_sentiment_analysis(text, adjectives, verbs, finbert_sentiment):\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    is_negation = False\n",
    "\n",
    "    # Check for negation\n",
    "    for word in words:\n",
    "        if word.lower() == \"not\":\n",
    "            is_negation = True\n",
    "            continue\n",
    "\n",
    "        word_score = custom_lexicon.get(word.lower(), 0)\n",
    "\n",
    "        if is_negation:\n",
    "            word_score = -word_score\n",
    "            is_negation = False\n",
    "\n",
    "        if word_score > 0:\n",
    "            positive_score += word_score\n",
    "        elif word_score < 0:\n",
    "            negative_score += abs(word_score)\n",
    "\n",
    "    # Add scores based on adjectives and verbs\n",
    "    for adj in adjectives:\n",
    "        if adj in custom_lexicon:\n",
    "            positive_score += custom_lexicon[adj] if custom_lexicon[adj] > 0 else 0\n",
    "            negative_score += abs(custom_lexicon[adj]) if custom_lexicon[adj] < 0 else 0\n",
    "\n",
    "    for verb in verbs:\n",
    "        if verb in custom_lexicon:\n",
    "            positive_score += custom_lexicon[verb] if custom_lexicon[verb] > 0 else 0\n",
    "            negative_score += abs(custom_lexicon[verb]) if custom_lexicon[verb] < 0 else 0\n",
    "\n",
    "    # Determine sentiment based on scores and FinBERT sentiment\n",
    "    final_sentiment = finbert_sentiment\n",
    "\n",
    "    # Combine FinBERT sentiment with adjective/verb analysis\n",
    "    if positive_score > negative_score:\n",
    "        final_sentiment = \"Positive\"\n",
    "    elif negative_score > positive_score:\n",
    "        final_sentiment = \"Negative\"\n",
    "\n",
    "    return final_sentiment\n",
    "\n",
    "# Extract adjectives and verbs\n",
    "df['Adjectives'], df['Verbs'] = zip(*df['Cleaned_Content'].apply(extract_adj_verbs))\n",
    "\n",
    "# Apply FinBERT sentiment analysis\n",
    "df['FinBERT_Sentiment'] = df['Cleaned_Content'].apply(lambda x: nlp(x)[0]['label'])\n",
    "\n",
    "# Apply the enhanced sentiment analysis function to each row\n",
    "df['Enhanced_NLTK_Sentiment'] = df.apply(\n",
    "    lambda row: enhanced_sentiment_analysis(row['Cleaned_Content'], row['Adjectives'], row['Verbs'], row['FinBERT_Sentiment']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the DataFrame with the new sentiment columns\n",
    "df[['Headlines', 'Cleaned_Content', 'FinBERT_Sentiment', 'Enhanced_NLTK_Sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enhanced_NLTK_Sentiment\n",
       "Neutral     1224\n",
       "Positive    1133\n",
       "Negative     443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Enhanced_NLTK_Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/simranjeetsingh1497/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load pre-trained Word2Vec or GloVe model\n",
    "# For example, load GloVe vectors (download from Stanford GloVe site if needed)\n",
    "word_vectors = KeyedVectors.load_word2vec_format('glove.6B.100d.txt', binary=False, no_header=True)\n",
    "# Replace 'path/to/glove.6B.100d.txt' with actual path to the GloVe file\n",
    "\n",
    "# Extract words from VADER lexicon and filter those in embedding model\n",
    "vader_lexicon = sia.lexicon\n",
    "vader_words = {word: word_vectors[word] for word in vader_lexicon if word in word_vectors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract words from VADER lexicon and filter those in embedding model\n",
    "vader_lexicon = sia.lexicon\n",
    "vader_words = {word: word_vectors[word] for word in vader_lexicon if word in word_vectors}\n",
    "\n",
    "# Pre-calculate matrix of VADER word embeddings for efficient similarity calculations\n",
    "vader_matrix = np.array(list(vader_words.values()))\n",
    "vader_word_list = list(vader_words.keys())\n",
    "\n",
    "# Caching dictionary for OOV words\n",
    "oov_cache = {}\n",
    "\n",
    "# Function to find the closest VADER word using cosine similarity\n",
    "def get_closest_vader_score(word):\n",
    "    if word in oov_cache:\n",
    "        return oov_cache[word]\n",
    "\n",
    "    if word in word_vectors:\n",
    "        word_vector = word_vectors[word].reshape(1, -1)\n",
    "        # Calculate cosine similarity for the word vector against all VADER words in one operation\n",
    "        similarities = cosine_similarity(word_vector, vader_matrix).flatten()\n",
    "        max_index = np.argmax(similarities)\n",
    "        closest_word = vader_word_list[max_index]\n",
    "        score = vader_lexicon[closest_word]\n",
    "    else:\n",
    "        score = 0  # Neutral score for words without embeddings\n",
    "\n",
    "    # Cache result for the word to avoid re-calculation\n",
    "    oov_cache[word] = score\n",
    "    return score\n",
    "\n",
    "\n",
    "# Find new sentiments for rows labeled as Neutral\n",
    "neutral_rows = df[df['Enhanced_NLTK_Sentiment'] == 'Neutral'].index\n",
    "\n",
    "for index in neutral_rows:\n",
    "    words = df.loc[index, 'Cleaned_Content'].split()\n",
    "    scores = [get_closest_vader_score(word) for word in words]\n",
    "    avg_score = np.mean(scores)  # Average score of words\n",
    "\n",
    "    # Classify based on score\n",
    "    if avg_score >= 0.05:\n",
    "        df.loc[index, 'Enhanced_NLTK_Sentiment'] = 'Positive'\n",
    "    elif avg_score <= -0.05:\n",
    "        df.loc[index, 'Enhanced_NLTK_Sentiment'] = 'Negative'\n",
    "    else:\n",
    "        df.loc[index, 'Enhanced_NLTK_Sentiment'] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Charts suggest the S&P 500 climb will stall out at the end of July, Jim Cramer warns'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Enhanced_NLTK_Sentiment']=='Negative'][['Headlines', 'Enhanced_NLTK_Sentiment']].iloc[4]['Headlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enhanced_NLTK_Sentiment\n",
       "Positive    2124\n",
       "Negative     616\n",
       "Neutral       60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Enhanced_NLTK_Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.20 ('hyper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bab37af7523904e79c92131fb0347e5bedb6e902b96b283136b723ec9c002450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
